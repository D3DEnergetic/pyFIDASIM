from pathlib import Path
import numpy as np

try:
    import numba
    numba_is_available = True
except:
    numba_is_available = False
    print('Numba is not available; consider installing Numba')

def conditional_numba(skip_numba=False):
    def decorator(func):
        if numba_is_available and not skip_numba:
            return numba.jit(func, cache=True, nopython=True, nogil=True)
        else:
            return func
    return decorator

def read_table(filename, plus=False):
    '''
    Routine to read FIDASIM binary files that contain the rates coefficients used 
    to track markers through the simulation grid. The tables have been generated by
    an IDL script and are based on cross-sections from JANEV-SMITH and ADAS.

    Parameters
    ----------
    filename : string()
        name of a given table (there are tables for electrons, ions, impurities, neutrals)
    plus : boolean, optional
        This switch allows one to only output the data array without information on the 
        axes. The default is False.

    Returns
    -------
    nti : int
        number of temperature bins
    dti_log : float
        binsize of the T-array
    minti_log : float
        minimum value of the T array
    neb: int
        number of energy bins
    deb_log : float
        binsize of the energy array
    mineb_log : float
        minium energy of the energy array
    nlev : int
        number of principal quantum states considered in the tables
    data : float array (nlevs+1, nlevs,neb,nti)
        This array contains the rates
    '''
    if isinstance(filename, Path):
        filename = filename.as_posix()
    with open(filename, 'rb') as fh:
        nti = np.fromfile(fh, dtype=np.int32, count=1)[0]
        dti_log = np.fromfile(fh, dtype=np.float64, count=1)[0]
        minti_log = np.fromfile(fh, dtype=np.float64, count=1)[0]
        neb = np.fromfile(fh, dtype=np.int32, count=1)[0]
        deb_log = np.fromfile(fh, dtype=np.float64, count=1)[0]
        mineb_log = np.fromfile(fh, dtype=np.float64, count=1)[0]
        nlev = np.fromfile(fh, dtype=np.int32, count=1)[0]
        data = np.fromfile(fh, dtype=np.float64)
        data = np.array(np.reshape(data, [nlev + 1, nlev, neb, nti], order='F'))
    if plus is False:
        return data
    else:
        return nti, dti_log, minti_log, neb, deb_log, mineb_log, nlev, data


def read_einstein(filename='tables/einstein.dat'):
    '''
    Routine to read the Einstein coefficients for spontaneous decay  / photon emission

    Parameters
    ----------
    filename : string, optional
        File geneated based on quantum mechanics calculations by R. Dux.
        The default is 'tables/einstein.dat'.

    Returns
    -------
    eins : float array (nlev,nlev)
        array of einstein coefficients

    '''
    with open(filename, 'rb') as fh:
        line = fh.readline()
        line = fh.readline()
        line = fh.readline()
        n = float(line.decode('utf-8'))
        a = []
        while line:
            line = fh.readline()
            try:
                a.append(float(line.decode('utf-8')))
            except BaseException:
                continue
        a = np.array(a)
        n = int(n)
        eins = np.reshape(a, [n, n], order='F')
    return eins


def load_tables(path_to_tables=None,pkl_filename='fidasim_tables.pkl'):
    '''
    This routine loads the tables containing effective rate coefficients as needed 
    by the collisinal radiative model of pyfidasim. One can either load binary files (load raw data)
    or one can choose to load an hdf file (path_to_table)

    Parameters
    ----------
    path_to_tables : string(), optional
        One can specify an "hdf5" file which contains the tables. The default is None.
    pkl_filename : TYPE, optional
        DESCRIPTION. The default is 'fidasim_tables.pkl'.

    Raises
    ------
    AttributeError
        DESCRIPTION.

    Returns
    -------
    tables : TYPE
        DESCRIPTION.

    '''
    ## the following code defines the directory containing the tables.
    ## "__file__" is this current "cr_model.py" file. We start with the path 
    ## where this file is, and then go to the parent directory. Then we go into
    ## '/tables'.
    if path_to_tables is None:
        from pyfidasim import tables
        tablesdir = Path(tables.__file__).parent
    else:
        tablesdir = Path(path_to_tables)

    ## combine the two strings
    tablespkl = tablesdir / pkl_filename
    if tablespkl.exists():
        from pyfidasim.toolbox import load_dict
        print(f'Loading atomic data in {tablespkl.as_posix()}')
        tables = load_dict(tablespkl.as_posix())
        return tables
    else:
        print(tablespkl, 'does not exist.')
        raise
        
    return tables

from numba import njit

@njit(cache=True)
def table_interp(table, elogs, tlogs, elogax, tlogax):
    """
    Bilinear interpolation in log10 space over (elog, tlog) with scalar loops.
    table: (m, n, nE, nT) of log10(coeff)
    returns: (len(elogs), m, n) in linear space
    """
    LN10 = 2.302585092994046  # log(10)

    m, n, nE, nT = table.shape
    ne = elogs.shape[0]

    # Precompute increments and reciprocals (uniform axes assumed)
    e0 = elogax[0]
    t0 = tlogax[0]
    dE = elogax[1] - e0
    dT = tlogax[1] - t0
    inv_dE = 1.0 / dE
    inv_dT = 1.0 / dT

    # Clip bounds (avoid top-edge overflow)
    emax = 0.999 * elogax[-1]
    tmax = 0.999 * tlogax[-1]

    # Outputs
    out = np.empty((ne, m, n), np.float64)

    # Precompute per-sample bins and fractional positions (no big arrays needed)
    for i in range(ne):
        # clamp
        e = elogs[i]
        if e < e0: e = e0
        if e > emax: e = emax
        t = tlogs[i]
        if t < t0: t = t0
        if t > tmax: t = tmax

        # indices (grid is uniform & inputs are >= start, so int cast == floor)
        ei = int((e - e0) * inv_dE)
        ti = int((t - t0) * inv_dT)
        if ei > nE - 2: ei = nE - 2
        if ti > nT - 2: ti = nT - 2

        # local fractional coords in cell
        er = (e - (e0 + ei * dE)) * inv_dE
        tr = (t - (t0 + ti * dT)) * inv_dT

        # bilinear weights: e0/e1 * t0/t1
        e0w = 1.0 - er
        e1w = er
        t0w = 1.0 - tr
        t1w = tr
        w00 = e0w * t0w
        w01 = e0w * t1w
        w10 = e1w * t0w
        w11 = e1w * t1w

        # Interpolate per (m, n) **without** allocating (m×n) temporaries
        for a in range(m):
            for b in range(n):
                c00 = table[a, b, ei,     ti    ]
                c01 = table[a, b, ei,     ti + 1]
                c10 = table[a, b, ei + 1, ti    ]
                c11 = table[a, b, ei + 1, ti + 1]
                logv = w00 * c00 + w01 * c01 + w10 * c10 + w11 * c11
                out[i, a, b] = np.exp(logv * LN10)  # 10**logv

    return out

@njit(cache=True, fastmath=False)  # Let MKL/OpenBLAS thread; Numba doesn't need to.
def colrad(dt, A, states):
    """
    Batched collisional–radiative step via diagonalization.

    Args
    ----
    dt      : (N,)          float64
    A       : (N, m, m)     float64 (or complex128) rate matrices
    states  : (N, m)        float64 initial state vectors

    Returns
    -------
    states_updated_all : (N, m) float64
        x(t+dt) = V * exp(L*dt) * V^{-1} * x(t)
    dens_all : (N, m) float64
        ∫_{t}^{t+dt} x(τ) dτ = V * ((exp(L*dt)-I) * L^{-1}) * V^{-1} * x(t)

    Notes
    -----
    * Works internally in complex128 to keep Numba’s typer from crying.
    * Avoids explicit matrix inverse; uses a single solve per item.
    * Handles small eigenvalues with a safe factor.
    * If dt[i] ≈ 0, skips the eigendecomposition entirely.
    """
    N = A.shape[0]
    m = A.shape[1]  # assume square

    states_updated_all = np.zeros((N, m), np.float64)
    dens_all           = np.zeros((N, m), np.float64)

    # Preallocate temporaries (reused per item)
    rhs  = np.empty(m, np.complex128)
    coef = np.empty(m, np.complex128)
    z    = np.empty(m, np.complex128)
    ez   = np.empty(m, np.complex128)
    sf   = np.empty(m, np.complex128)

    for i in range(N):
        ti = dt[i]
        # Short-circuit tiny steps
        if np.abs(ti) < 1e-15:
            states_updated_all[i, :] = states[i, :]
            # dens_all remains zeros
            continue

        # Promote to complex, once
        Ai = A[i].astype(np.complex128)

        # Eigen-decomposition: Ai = V Λ V^{-1}
        # NumPy returns eigenvectors as COLUMNS of V
        w, V = np.linalg.eig(Ai)  # w: (m,), V: (m, m)

        # rhs = states[i] (complex)
        for j in range(m):
            rhs[j] = states[i, j]

        # Solve V * coef = rhs   (no inv(V))
        coef = np.linalg.solve(V, rhs)

        # z = w * dt, ez = exp(z)
        for j in range(m):
            z[j]  = w[j] * ti
            ez[j] = np.exp(z[j])

        # Safe integral factor: (exp(z)-1)/w, with w≈0 -> dt
        for j in range(m):
            lam = w[j]
            if np.abs(lam) < 1e-12:
                sf[j] = ti
            else:
                sf[j] = (ez[j] - 1.0) / lam  # (expm1 not always supported for complex in numba)

        # Back transforms
        tmp = coef * ez
        x_next_c = V @ tmp

        tmp = coef * sf
        den_c = V @ tmp

        # Physical results should be real
        for j in range(m):
            states_updated_all[i, j] = x_next_c[j].real
            dens_all[i, j]           = den_c[j].real

    return states_updated_all, dens_all